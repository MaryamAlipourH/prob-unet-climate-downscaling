{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prob_unet_utils import compute_annual_block_maxima, gev_return_level, gev_parametric_bootstrap, get_empirical_return_periods\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import climex_utils as cu\n",
    "from scipy.stats import genextreme\n",
    "import matplotlib.pyplot as plt\n",
    "import train_prob_unet_model as tm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version\n",
    "args = tm.get_args()\n",
    "def set_seed(seed):\n",
    "    random.seed(seed) \n",
    "    np.random.seed(seed)  \n",
    "    torch.manual_seed(seed) \n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# -- 1) Set seed for reproducibility\n",
    "set_seed(42) \n",
    "\n",
    "def compute_return_levels_for_random_pixel(\n",
    "    model,\n",
    "    dataset,\n",
    "    device,\n",
    "    years,             \n",
    "    num_samples=10,    \n",
    "    chosen_pixel=None,\n",
    "    variable='pr'   \n",
    "):\n",
    "    \"\"\"\n",
    "    Generate daily variable at one pixel across all days and multiple ensemble draws.\n",
    "    Fit GEV, compute return levels, and do param. bootstrap for confidence intervals.\n",
    "    \"\"\"\n",
    "\n",
    "    if chosen_pixel is None:\n",
    "        # pick random pixel within the domain\n",
    "        chosen_pixel = (random.randint(0,127), random.randint(0,127))\n",
    "    pix_y, pix_x = chosen_pixel\n",
    "\n",
    "    print(f\"\\n[INFO] Computing return levels at pixel = ({pix_y}, {pix_x}).\")\n",
    "    print(f\"\\n[INFO] number of samples = {num_samples}\")\n",
    "    print(f\"\\n[INFO] variable = {variable}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    total_days = len(dataset)  \n",
    "    # we'll store daily_data shape: [total_days, num_samples]\n",
    "    daily_data = np.zeros((total_days, num_samples), dtype=np.float32)\n",
    "\n",
    "    # Iterate over each day\n",
    "    for day_idx in range(total_days):\n",
    "        sample_dict = dataset[day_idx]   # This loads a single day from dataset\n",
    "        # Prepare inputs\n",
    "        inputs = sample_dict['inputs'].unsqueeze(0).to(device)   # shape [1, C, H, W]\n",
    "        lrinterp = sample_dict['lrinterp'].unsqueeze(0).to(device)\n",
    "        timestamps = sample_dict['timestamps'].unsqueeze(0).to(device)\n",
    "\n",
    "        # We'll produce 'num_samples' draws from the model\n",
    "        for r in range(num_samples):\n",
    "            # forward pass\n",
    "            with torch.no_grad():\n",
    "                output = model(inputs, t=timestamps, training=False)\n",
    "            \n",
    "            # convert from residual to actual\n",
    "            # shape [1, nvars, H, W]\n",
    "            hr_pred = dataset.residual_to_hr(output.cpu(), lrinterp.cpu())\n",
    "\n",
    "            if variable == 'pr':\n",
    "                # For precipitation: use softplus and unit conversion (kg/m²/s to mm/day)\n",
    "                pr_val = cu.softplus(hr_pred[:, 0])\n",
    "                pr_val = cu.kgm2sTommday(pr_val)\n",
    "                pixel_val = pr_val[0, pix_y, pix_x].item()\n",
    "            elif variable == 'tasmax':\n",
    "                # For tasmax: compute as softplus(channel 2, c=0) + channel 1, then convert from Kelvin to Celsius\n",
    "                tasmax = hr_pred[:, 1] + cu.softplus(hr_pred[:, 2], c=0)\n",
    "                tasmax = cu.KToC(tasmax)\n",
    "                pixel_val = tasmax[0, pix_y, pix_x].item()\n",
    "            elif variable == 'tasmin':\n",
    "                tasmin = hr_pred[:, 1]  # No transformation needed for tasmin\n",
    "                tasmin = cu.KToC(tasmin)\n",
    "                pixel_val = tasmin[0, pix_y, pix_x].item()\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported variable. Use 'pr', 'tasmax' or 'tasmin'.\")\n",
    "\n",
    "            daily_data[day_idx, r] = pixel_val\n",
    "\n",
    "    # Now daily_data shape = [total_days, num_samples]. We should have the entire record.\n",
    "\n",
    "    # Next: get block maxima. We must know how many years we have and days_per_year\n",
    "    days_per_year = 365 \n",
    "    n_years = len(years) \n",
    "    # check total_days == n_years * days_per_year, or adapt as needed\n",
    "    print(f\"Total days = {total_days}, years = {n_years}, days_per_year = {days_per_year}\")\n",
    "    \n",
    "    block_maxima = compute_annual_block_maxima(daily_data, years, days_per_year=days_per_year)\n",
    "    # block_maxima => shape (#years * num_samples,)\n",
    "\n",
    "    # Fit GEV\n",
    "    shape_hat, loc_hat, scale_hat = genextreme.fit(block_maxima)\n",
    "    print(f\"GEV fit => shape={shape_hat:.3f}, loc={loc_hat:.3f}, scale={scale_hat:.3f}\")\n",
    "\n",
    "    np.save(f\"{args.plotdir}/pixel_{pix_y}_{pix_x}_block_maxima.npy\", block_maxima)\n",
    "\n",
    "    # We define which return periods we want\n",
    "    return_periods = [1.1 ,2, 5, 10, 20, 50, 100, 200, 300, 500, 700, 1000]\n",
    "    # Compute return levels\n",
    "    rl_values = [gev_return_level(shape_hat, loc_hat, scale_hat, T) for T in return_periods]\n",
    "\n",
    "    # Bootstrap for confidence intervals\n",
    "    rl_boot = gev_parametric_bootstrap(shape_hat, loc_hat, scale_hat,\n",
    "                                       sample_size=len(block_maxima),\n",
    "                                       return_periods=return_periods,\n",
    "                                       n_bootstrap=1000)  \n",
    "\n",
    "    rl_ci_lower = {}\n",
    "    rl_ci_upper = {}\n",
    "    for T in return_periods:\n",
    "        vals_T = np.array(rl_boot[T])\n",
    "        rl_ci_lower[T] = np.percentile(vals_T, 2.5)\n",
    "        rl_ci_upper[T] = np.percentile(vals_T, 97.5)\n",
    "\n",
    "    print(\"\\nReturn Levels (mm/day) with 95% CI at the chosen pixel:\")\n",
    "    for T, rl in zip(return_periods, rl_values):\n",
    "        ci_low = rl_ci_lower[T]\n",
    "        ci_high = rl_ci_upper[T]\n",
    "        print(f\"  {T:g}-year RL = {rl:.2f}  [95% CI: {ci_low:.2f}, {ci_high:.2f}]\")\n",
    "\n",
    "\n",
    "  \n",
    "    plt.figure(figsize=(8,5))\n",
    "    Ts = np.array(return_periods)\n",
    "    rl_means = np.array(rl_values)\n",
    "    rl_low = np.array([rl_ci_lower[T] for T in return_periods])\n",
    "    rl_high= np.array([rl_ci_upper[T] for T in return_periods])\n",
    "\n",
    "    # Plot GEV fit as straight orange line without markers\n",
    "    plt.plot(Ts, rl_means, color='orange', linewidth=2, label='Fitted Return Level')\n",
    "    \n",
    "    # Plot confidence interval borders as black dashed lines without fill\n",
    "    plt.plot(Ts, rl_low, color='black', linestyle='--', linewidth=1, label='95% Confidence Interval')\n",
    "    plt.plot(Ts, rl_high, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Calculate empirical return periods and sort block maxima\n",
    "    sorted_maxima, empirical_T = get_empirical_return_periods(block_maxima)\n",
    "\n",
    "    # Plot the empirical points\n",
    "    plt.scatter(empirical_T, sorted_maxima, marker='o', color='blue', s=15, label='Model Predictions')\n",
    "\n",
    "    plt.xscale('log')\n",
    "    if variable == 'pr':\n",
    "        plt.ylabel('Precipitation (mm/day)')\n",
    "        # plt.title(f\"Precipitation GEV Return Levels at Pixel ({pix_y},{pix_x})\")\n",
    "    elif variable == 'tasmax':\n",
    "        plt.ylabel('Tasmax (°C)')\n",
    "        # plt.title(f\"Tasmax GEV Return Levels at Pixel ({pix_y},{pix_x})\")\n",
    "    elif variable == 'tasmin':\n",
    "        plt.ylabel('Tasmin (°C)')\n",
    "        # plt.title(f\"Tasmin GEV Return Levels at Pixel ({pix_y},{pix_x})\")\n",
    "\n",
    "    plt.xlabel('Return Period (years)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure or show\n",
    "    plt.savefig(f\"{args.plotdir}/pixel_{pix_y}_{pix_x}_return_levels.pdf\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    return daily_data, block_maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening and lazy loading netCDF files\n",
      "Loading dataset into memory\n",
      "Converting xarray Dataset to Pytorch tensor\n",
      "\n",
      "##########################################\n",
      "############ PROCESSING DONE #############\n",
      "##########################################\n",
      "\n",
      "Test dataset length (days): 10950\n"
     ]
    }
   ],
   "source": [
    "args.years_test = range(1998, 2028)\n",
    "dataset_test = cu.climex2torch(\n",
    "    datadir=args.datadir,\n",
    "    years=args.years_test,\n",
    "    variables=args.variables,\n",
    "    coords=args.coords,\n",
    "    lowres_scale=args.lowres_scale,\n",
    "    type=\"lrinterp_to_residuals\",\n",
    "    transfo=True\n",
    ")\n",
    "\n",
    "print(\"Test dataset length (days):\", len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prob_unet import ProbabilisticUNet\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create your model with the same structure:\n",
    "probunet_model = ProbabilisticUNet(\n",
    "    input_channels=len(args.variables),\n",
    "    num_classes=len(args.variables),\n",
    "    latent_dim=16,\n",
    "    num_filters=[32, 64, 128, 256],\n",
    "    model_channels=32,\n",
    "    channel_mult=[1, 2, 4, 8],\n",
    "    beta_0=0.0,\n",
    "    beta_1=0.0,\n",
    "    beta_2=0.0\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the trained weights\n",
    "checkpoint_path = \"./results/plots/03/28/202514:19:12/probunet_model_lat_dim_16.pth\"\n",
    "probunet_model.load_state_dict(\n",
    "    torch.load(checkpoint_path, map_location=device)\n",
    ")\n",
    "probunet_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Computing return levels at pixel = (56, 40).\n",
      "\n",
      "[INFO] number of samples = 10\n",
      "\n",
      "[INFO] variable = pr\n",
      "Computing statistics for standardization\n",
      "Total days = 10950, years = 30, days_per_year = 365\n",
      "GEV fit => shape=-0.366, loc=106.781, scale=50.022\n",
      "\n",
      "Return Levels (mm/day) with 95% CI at the chosen pixel:\n",
      "  1.1-year RL = 69.34  [95% CI: 37.98, 73.79]\n",
      "  2-year RL = 126.40  [95% CI: 42.73, 134.36]\n",
      "  5-year RL = 206.72  [95% CI: 94.94, 229.42]\n",
      "  10-year RL = 281.45  [95% CI: 243.04, 1066.77]\n",
      "  20-year RL = 375.22  [95% CI: 317.77, 12221.23]\n",
      "  50-year RL = 539.67  [95% CI: 432.79, 256006.86]\n",
      "  100-year RL = 705.33  [95% CI: 537.71, 2356517.72]\n",
      "  200-year RL = 918.26  [95% CI: 659.75, 24900588.36]\n",
      "  300-year RL = 1070.10  [95% CI: 745.35, 100438610.69]\n",
      "  500-year RL = 1296.29  [95% CI: 857.29, 581316768.47]\n",
      "  700-year RL = 1470.04  [95% CI: 942.96, 1846888518.91]\n",
      "  1000-year RL = 1679.09  [95% CI: 1041.77, 6287560116.75]\n"
     ]
    }
   ],
   "source": [
    "daily_data, block_maxima = compute_return_levels_for_random_pixel(\n",
    "    model=probunet_model,\n",
    "    dataset=dataset_test,\n",
    "    device=device,\n",
    "    years=args.years_test,      \n",
    "    num_samples=10,        \n",
    "    chosen_pixel=(56, 40),\n",
    "    variable= \"pr\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Computing return levels at pixel = (56, 40).\n",
      "\n",
      "[INFO] number of samples = 10\n",
      "\n",
      "[INFO] variable = tasmax\n",
      "Computing statistics for standardization\n",
      "Total days = 10950, years = 30, days_per_year = 365\n",
      "GEV fit => shape=0.156, loc=33.022, scale=1.973\n",
      "\n",
      "Return Levels (mm/day) with 95% CI at the chosen pixel:\n",
      "    2-year RL = 33.72  [95% CI: 33.47, 33.98]\n",
      "    5-year RL = 35.66  [95% CI: 35.34, 35.96]\n",
      "   10-year RL = 36.77  [95% CI: 36.38, 37.12]\n",
      "   20-year RL = 37.71  [95% CI: 37.21, 38.16]\n",
      "   50-year RL = 38.78  [95% CI: 38.10, 39.40]\n",
      "  100-year RL = 39.49  [95% CI: 38.67, 40.27]\n",
      "  200-year RL = 40.13  [95% CI: 39.14, 41.09]\n",
      "  300-year RL = 40.47  [95% CI: 39.38, 41.55]\n",
      "  500-year RL = 40.86  [95% CI: 39.65, 42.11]\n",
      "  700-year RL = 41.11  [95% CI: 39.82, 42.46]\n",
      "  1000-year RL = 41.35  [95% CI: 39.97, 42.81]\n"
     ]
    }
   ],
   "source": [
    "daily_data_tasmax, block_maxima_tasmax = compute_return_levels_for_random_pixel(\n",
    "    model=probunet_model,\n",
    "    dataset=dataset_test,\n",
    "    device=device,\n",
    "    years=args.years_test,      \n",
    "    num_samples=10,        \n",
    "    chosen_pixel=(56, 40),\n",
    "    variable= \"tasmax\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Computing return levels at pixel = (56, 40).\n",
      "\n",
      "[INFO] number of samples = 10\n",
      "\n",
      "[INFO] variable = tasmin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m daily_data_tasmin, block_maxima_tasmin \u001b[38;5;241m=\u001b[39m compute_return_levels_for_random_pixel(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mprobunet_model,\n\u001b[1;32m      3\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset_test,\n\u001b[1;32m      4\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m      5\u001b[0m     years\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39myears_test,      \n\u001b[1;32m      6\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,        \n\u001b[1;32m      7\u001b[0m     chosen_pixel\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m56\u001b[39m, \u001b[38;5;241m40\u001b[39m),\n\u001b[1;32m      8\u001b[0m     variable\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtasmin\u001b[39m\u001b[38;5;124m\"\u001b[39m    \n\u001b[1;32m      9\u001b[0m )\n",
      "Cell \u001b[0;32mIn[15], line 44\u001b[0m, in \u001b[0;36mcompute_return_levels_for_random_pixel\u001b[0;34m(model, dataset, device, years, num_samples, chosen_pixel, variable)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 44\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(inputs, t\u001b[38;5;241m=\u001b[39mtimestamps, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# convert from residual to actual\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# shape [1, nvars, H, W]\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     hr_pred \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mresidual_to_hr(output\u001b[38;5;241m.\u001b[39mcpu(), lrinterp\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/prob-unet-mds/prob_unet.py:209\u001b[0m, in \u001b[0;36mProbabilisticUNet.forward\u001b[0;34m(self, x, target, t, training)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03mForward pass of the Probabilistic U-Net.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    output (torch.Tensor): The model's output tensor.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Get features from the UNet backbone      \u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m unet_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet(x)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# During training, sample z from the posterior\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;129;01mand\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/prob-unet-mds/networks.py:322\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    320\u001b[0m skips \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 322\u001b[0m     x \u001b[38;5;241m=\u001b[39m block(x, emb) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(block, UNetBlock) \u001b[38;5;28;01melse\u001b[39;00m block(x)\n\u001b[1;32m    323\u001b[0m     skips\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskips_postunet \u001b[38;5;241m=\u001b[39m skips[:\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/prob-unet-mds/networks.py:168\u001b[0m, in \u001b[0;36mUNetBlock.forward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, emb):\n\u001b[1;32m    167\u001b[0m     orig \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 168\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv0(silu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm0(x)))\n\u001b[1;32m    170\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffine(emb)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madaptive_scale:\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1535\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1535\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1536\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "daily_data_tasmin, block_maxima_tasmin = compute_return_levels_for_random_pixel(\n",
    "    model=probunet_model,\n",
    "    dataset=dataset_test,\n",
    "    device=device,\n",
    "    years=args.years_test,      \n",
    "    num_samples=10,        \n",
    "    chosen_pixel=(56, 40),\n",
    "    variable= \"tasmin\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observed vs. Model Return Levels Analysis\n",
    "\n",
    "The plot comparing observed vs. model precipitation return levels reveals several important insights:\n",
    "\n",
    "## Why are there fewer blue crosses (observed empirical) than red crosses (model empirical)?\n",
    "\n",
    "This difference is due to sample size:\n",
    "- **Observed data**: We have 30 years (1998-2028) with 1 observation per year = 30 empirical points\n",
    "- **Model data**: We have 30 years with 30 samples per year = 900 empirical points (30×30)\n",
    "\n",
    "This 30x difference explains the density difference in empirical markers.\n",
    "\n",
    "## Interpretation of the Results:\n",
    "\n",
    "1. **Model Underestimation**: The model GEV curve (red) falls significantly below the observed GEV curve (blue), indicating that our model systematically underestimates precipitation extremes.\n",
    "\n",
    "2. **Statistical Significance**: The model curve falls outside the 95% confidence interval (blue shaded area) of observed GEV for most return periods, confirming this bias is statistically significant.\n",
    "\n",
    "3. **Distribution Behavior**: \n",
    "   - **Observed data**: The empirical blue crosses align well with the fitted GEV curve\n",
    "   - **Model data**: The empirical red crosses show a plateau around 75 mm/day, while the fitted model GEV continues rising - suggesting the model has an artificial ceiling for extreme precipitation\n",
    "\n",
    "4. **Return Period Sensitivity**: The underestimation grows more severe for longer return periods, indicating our model particularly struggles with very extreme events.\n",
    "\n",
    "5. **Physical Limitations**: The plateau in model empirical points suggests our probabilistic U-Net may have inherent limitations in generating sufficiently extreme precipitation events.\n",
    "\n",
    "This analysis confirms our professor's approach was valuable - comparing against observed data reveals systematic biases that weren't apparent when only analyzing the model's internal consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, numpy as np, torch, matplotlib.pyplot as plt\n",
    "from scipy.stats import genextreme\n",
    "import climex_utils as cu\n",
    "from scipy.interpolate import interp1d \n",
    "from prob_unet_utils import (\n",
    "    compute_annual_block_maxima, gev_return_level, gev_parametric_bootstrap,\n",
    "    get_empirical_return_periods\n",
    ")\n",
    "from prob_unet import ProbabilisticUNet\n",
    "import train_prob_unet_model as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = tm.get_args()\n",
    "def set_seed(seed):\n",
    "    random.seed(seed) \n",
    "    np.random.seed(seed)  \n",
    "    torch.manual_seed(seed) \n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "# -- 1) Set seed for reproducibility\n",
    "set_seed(42) \n",
    "\n",
    "# --- config (your list) ---\n",
    "model_paths = [\n",
    "    \"./results/plots/08/01/202508:49:05/probunet_model_lat_dim_16.pth\",  # λ=0\n",
    "    \"./results/plots/08/01/202508:23:04/probunet_model_lat_dim_16.pth\",  # λ=1\n",
    "    \"./results/plots/07/22/202512:51:39/probunet_model_lat_dim_16.pth\",  # λ=0.158\n",
    "    \"./results/plots/08/17/202515:50:03/probunet_model_lat_dim_16.pth\",  # afCRPS\n",
    "]\n",
    "labels = [r'$\\lambda=0$', r'$\\lambda=1$', r'$\\lambda=0.158$', 'afCRPS']\n",
    "\n",
    "# nice colors/markers per model\n",
    "colors  = ['#1f77b4', \"#F09A4E\", '#2ca02c', '#d62728']\n",
    "markers = ['o', 's', '^', 'D']\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# helpers\n",
    "# ---------------------------------------------------------------------\n",
    "def load_probunet_model(path: str, device: torch.device) -> ProbabilisticUNet:\n",
    "    m = ProbabilisticUNet(\n",
    "        input_channels=len(args.variables),\n",
    "        num_classes=len(args.variables),\n",
    "        latent_dim=16,\n",
    "        num_filters=[32, 64, 128, 256],\n",
    "        model_channels=32,\n",
    "        channel_mult=[1, 2, 4, 8],\n",
    "        beta_0=0.0, beta_1=0.0, beta_2=0.0\n",
    "    ).to(device)\n",
    "    sd = torch.load(path, map_location=device)\n",
    "    m.load_state_dict(sd)\n",
    "    m.eval()\n",
    "    return m\n",
    "\n",
    "def extract_pixel_gt(series_item, variable: str, y: int, x: int) -> float:\n",
    "    \"\"\"series_item is dataset[day_idx]; returns GT value at pixel (y,x) in real units.\"\"\"\n",
    "    hr = series_item['hr']  # [3, H, W] in transfo domain (since dataset built with transfo=True)\n",
    "    if variable == 'pr':\n",
    "        val = cu.kgm2sTommday(cu.softplus(hr[0]))[y, x].item()\n",
    "    elif variable == 'tasmax':\n",
    "        val = cu.KToC(cu.softplus(hr[2], c=0) + hr[1])[y, x].item()\n",
    "    elif variable == 'tasmin':\n",
    "        val = cu.KToC(hr[1])[y, x].item()\n",
    "    else:\n",
    "        raise ValueError(\"variable must be 'pr', 'tasmax', or 'tasmin'\")\n",
    "    return float(val)\n",
    "\n",
    "def extract_pixel_from_model(model, series_item, device, variable: str, y: int, x: int, num_samples: int):\n",
    "    \"\"\"Returns [num_samples] values at (y,x) for one day from a model ensemble.\"\"\"\n",
    "    inputs     = series_item['inputs'].unsqueeze(0).to(device)    # [1,C,H,W] (transfo)\n",
    "    lrinterp   = series_item['lrinterp'].unsqueeze(0).to(device)  # [1,C,H,W] (transfo)\n",
    "    timestamps = series_item['timestamps'].unsqueeze(0).to(device)\n",
    "    vals = np.zeros((num_samples,), dtype=np.float32)\n",
    "    with torch.no_grad():\n",
    "        for r in range(num_samples):\n",
    "            out_residual = model(inputs, t=timestamps, training=False)        # [1,C,H,W] residual/transfo\n",
    "            out_hr_trans = dataset_test.residual_to_hr(out_residual.cpu(), lrinterp.cpu())  # [1,C,H,W], transfo\n",
    "            if variable == 'pr':\n",
    "                pr = cu.kgm2sTommday(cu.softplus(out_hr_trans[:,0]))          # mm/day\n",
    "                vals[r] = pr[0, y, x].item()\n",
    "            elif variable == 'tasmax':\n",
    "                tmax = cu.KToC(out_hr_trans[:,1] + cu.softplus(out_hr_trans[:,2], c=0))\n",
    "                vals[r] = tmax[0, y, x].item()\n",
    "            elif variable == 'tasmin':\n",
    "                tmin = cu.KToC(out_hr_trans[:,1])\n",
    "                vals[r] = tmin[0, y, x].item()\n",
    "    return vals  # shape [num_samples]\n",
    "\n",
    "def fit_gev_from_blockmax(block_maxima, return_periods, n_bootstrap=1000):\n",
    "    shape_hat, loc_hat, scale_hat = genextreme.fit(block_maxima)\n",
    "    rl_curve = [gev_return_level(shape_hat, loc_hat, scale_hat, T) for T in return_periods]\n",
    "    boot = gev_parametric_bootstrap(\n",
    "        shape_hat, loc_hat, scale_hat,\n",
    "        sample_size=len(block_maxima),\n",
    "        return_periods=return_periods,\n",
    "        n_bootstrap=n_bootstrap\n",
    "    )\n",
    "    rl_low  = {T: np.percentile(boot[T],  2.5) for T in return_periods}\n",
    "    rl_high = {T: np.percentile(boot[T], 97.5) for T in return_periods}\n",
    "    return (shape_hat, loc_hat, scale_hat), rl_curve, rl_low, rl_high\n",
    "\n",
    "def make_return_level_plot(variable, pixel, gt_params, return_periods, rl_curve, rl_low, rl_high, model_empirical, save_dir):\n",
    "    ylab = {'pr': 'Precipitation (mm/day)', 'tasmax': 'Tasmax (°C)', 'tasmin': 'Tasmin (°C)'}[variable]\n",
    "    Ts = np.array(return_periods)\n",
    "    rl_mean = np.array(rl_curve)\n",
    "    rl_lo   = np.array([rl_low[T]  for T in return_periods])\n",
    "    rl_hi   = np.array([rl_high[T] for T in return_periods])\n",
    "\n",
    "    plt.figure(figsize=(7.2, 4.6))\n",
    "    # GT fitted RL + CI\n",
    "    plt.plot(Ts, rl_mean, color='grey', linewidth=2.2, label='GEV fit (GT)')\n",
    "    plt.plot(Ts, rl_lo,  color='black', linestyle='--', linewidth=1.1, label='95% CI (GT)')\n",
    "    plt.plot(Ts, rl_hi,  color='black', linestyle='--', linewidth=1.1)\n",
    "\n",
    "    # Empirical points per model\n",
    "    for (lab, col, mkr), (emp_T, emp_vals) in zip(zip(labels, colors, markers), model_empirical):\n",
    "        plt.scatter(emp_T, emp_vals, s=18, color=col, marker=mkr, label=lab, alpha=0.9)\n",
    "\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Return period (years)')\n",
    "    plt.ylabel(ylab)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='upper left', frameon=True, ncol=2)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    fname = os.path.join(save_dir, f\"return_levels_{variable}_y{pixel[0]}_x{pixel[1]}.pdf\")\n",
    "    plt.savefig(fname, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved: {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening and lazy loading netCDF files\n",
      "Loading dataset into memory\n",
      "Converting xarray Dataset to Pytorch tensor\n",
      "\n",
      "##########################################\n",
      "############ PROCESSING DONE #############\n",
      "##########################################\n",
      "\n",
      "Test dataset length (days): 10950\n"
     ]
    }
   ],
   "source": [
    "args.years_test = range(1998, 2028)\n",
    "dataset_test = cu.climex2torch(\n",
    "    datadir=args.datadir,\n",
    "    years=args.years_test,\n",
    "    variables=args.variables,\n",
    "    coords=args.coords,\n",
    "    lowres_scale=args.lowres_scale,\n",
    "    type=\"lrinterp_to_residuals\",\n",
    "    transfo=True\n",
    ")\n",
    "\n",
    "print(\"Test dataset length (days):\", len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset length (days): 10950\n",
      "\n",
      "=== Variable: pr ===\n",
      "Computing statistics for standardization\n",
      "Bootstrap: kept 1000/1000 valid samples\n",
      "GEV (GT) params: shape=-0.019, loc=59.091, scale=15.112\n",
      "  -> Sampling model $\\lambda=0$\n",
      "  -> Sampling model $\\lambda=1$\n",
      "  -> Sampling model $\\lambda=0.158$\n",
      "  -> Sampling model afCRPS\n",
      "Saved: ./results/plots/08/21/202521:59:44/return_levels_multi_model/return_levels_pr_y55_x110.pdf\n",
      "\n",
      "=== Variable: tasmax ===\n",
      "Bootstrap: kept 1000/1000 valid samples\n",
      "GEV (GT) params: shape=0.211, loc=23.952, scale=1.109\n",
      "  -> Sampling model $\\lambda=0$\n",
      "  -> Sampling model $\\lambda=1$\n",
      "  -> Sampling model $\\lambda=0.158$\n",
      "  -> Sampling model afCRPS\n",
      "Saved: ./results/plots/08/21/202521:59:44/return_levels_multi_model/return_levels_tasmax_y55_x110.pdf\n",
      "\n",
      "=== Variable: tasmin ===\n",
      "Bootstrap: kept 1000/1000 valid samples\n",
      "GEV (GT) params: shape=0.140, loc=20.303, scale=0.786\n",
      "  -> Sampling model $\\lambda=0$\n",
      "  -> Sampling model $\\lambda=1$\n",
      "  -> Sampling model $\\lambda=0.158$\n",
      "  -> Sampling model afCRPS\n",
      "Saved: ./results/plots/08/21/202521:59:44/return_levels_multi_model/return_levels_tasmin_y55_x110.pdf\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# main: GT GEV + four model empirical curves, per variable\n",
    "# ---------------------------------------------------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "chosen_pixel = (55, 110)     # change if you like\n",
    "num_samples  = 5          # ensemble draws per model & day\n",
    "days_per_year = 365\n",
    "years = list(args.years_test)\n",
    "save_dir = os.path.join(args.plotdir, \"return_levels_multi_model\")\n",
    "\n",
    "# Ensure dataset_test already exists (from your previous cell)\n",
    "print(\"Test dataset length (days):\", len(dataset_test))\n",
    "\n",
    "# Trim series to an integer number of years if needed\n",
    "N_expected = len(years) * days_per_year\n",
    "if len(dataset_test) < N_expected:\n",
    "    raise RuntimeError(f\"Dataset shorter than expected: {len(dataset_test)} < {N_expected}\")\n",
    "elif len(dataset_test) > N_expected:\n",
    "    print(f\"[WARN] Trimming dataset from {len(dataset_test)} to {N_expected} days to match {len(years)} years.\")\n",
    "    idx_keep = N_expected  # keep first N_expected days\n",
    "\n",
    "# Loop over variables\n",
    "for variable in ['pr', 'tasmax', 'tasmin']: \n",
    "    print(f\"\\n=== Variable: {variable} ===\")\n",
    "    y, x = chosen_pixel\n",
    "\n",
    "    # ---- Ground truth daily series at (y,x) ----\n",
    "    gt_daily = np.zeros((N_expected, 1), dtype=np.float32)\n",
    "    for d in range(N_expected):\n",
    "        item = dataset_test[d]\n",
    "        gt_daily[d, 0] = extract_pixel_gt(item, variable, y, x)\n",
    "\n",
    "    # Block maxima from GT and GEV fit\n",
    "    block_gt = compute_annual_block_maxima(gt_daily, years, days_per_year=days_per_year)\n",
    "    return_periods = [1.1, 2, 5, 10, 20, 50, 100, 300]\n",
    "    (shape_hat, loc_hat, scale_hat), rl_curve, rl_low, rl_high = fit_gev_from_blockmax(\n",
    "        block_gt, return_periods, n_bootstrap=1000\n",
    "    )\n",
    "    print(f\"GEV (GT) params: shape={shape_hat:.3f}, loc={loc_hat:.3f}, scale={scale_hat:.3f}\")\n",
    "\n",
    "    # ---- Models: empirical RL points (no re-fit) ----\n",
    "    model_empirical = []  # list of tuples (empirical_T, sorted_maxima) in plotting order\n",
    "    for path, lab in zip(model_paths, labels):\n",
    "        print(f\"  -> Sampling model {lab}\")\n",
    "        model = load_probunet_model(path, device)\n",
    "        daily_model = np.zeros((N_expected, num_samples), dtype=np.float32)\n",
    "        for d in range(N_expected):\n",
    "            item = dataset_test[d]\n",
    "            daily_model[d, :] = extract_pixel_from_model(\n",
    "                model, item, device, variable, y, x, num_samples=num_samples\n",
    "            )\n",
    "        block_m = compute_annual_block_maxima(daily_model, years, days_per_year=days_per_year)\n",
    "        sorted_maxima, empirical_T = get_empirical_return_periods(block_m)\n",
    "        model_empirical.append((empirical_T, sorted_maxima))\n",
    "\n",
    "    # ---- Plot: one GT curve/CI + four model empirical sets ----\n",
    "    make_return_level_plot(\n",
    "        variable=variable,\n",
    "        pixel=chosen_pixel,\n",
    "        gt_params=(shape_hat, loc_hat, scale_hat),\n",
    "        return_periods=return_periods,\n",
    "        rl_curve=rl_curve,\n",
    "        rl_low=rl_low,\n",
    "        rl_high=rl_high,\n",
    "        model_empirical=model_empirical,\n",
    "        save_dir=save_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
