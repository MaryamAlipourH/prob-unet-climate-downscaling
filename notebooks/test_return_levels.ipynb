{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prob_unet_utils import compute_annual_block_maxima, gev_return_level, gev_parametric_bootstrap\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import climex_utils as cu\n",
    "from scipy.stats import genextreme\n",
    "import matplotlib.pyplot as plt\n",
    "import train_prob_unet_model as tm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = tm.get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prob_unet_utils import get_empirical_return_periods\n",
    "def compute_return_levels_for_random_pixel(\n",
    "    model,\n",
    "    dataset,\n",
    "    device,\n",
    "    years,             \n",
    "    num_samples=10,    \n",
    "    chosen_pixel=None,\n",
    "    variable='pr'   \n",
    "):\n",
    "    \"\"\"\n",
    "    Generate daily variable at one pixel across all days and multiple ensemble draws.\n",
    "    Fit GEV, compute return levels, and do param. bootstrap for confidence intervals.\n",
    "    \"\"\"\n",
    "\n",
    "    if chosen_pixel is None:\n",
    "        # pick random pixel within the domain\n",
    "        chosen_pixel = (random.randint(0,127), random.randint(0,127))\n",
    "    pix_y, pix_x = chosen_pixel\n",
    "\n",
    "    print(f\"\\n[INFO] Computing return levels at pixel = ({pix_y}, {pix_x}).\")\n",
    "    print(f\"\\n[INFO] number of samples = {num_samples}\")\n",
    "    print(f\"\\n[INFO] variable = {variable}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    total_days = len(dataset)  \n",
    "    # we'll store daily_data shape: [total_days, num_samples]\n",
    "    daily_data = np.zeros((total_days, num_samples), dtype=np.float32)\n",
    "\n",
    "    # Iterate over each day\n",
    "    for day_idx in range(total_days):\n",
    "        sample_dict = dataset[day_idx]   # This loads a single day from dataset\n",
    "        # Prepare inputs\n",
    "        inputs = sample_dict['inputs'].unsqueeze(0).to(device)   # shape [1, C, H, W]\n",
    "        lrinterp = sample_dict['lrinterp'].unsqueeze(0).to(device)\n",
    "        timestamps = sample_dict['timestamps'].unsqueeze(0).to(device)\n",
    "\n",
    "        # We'll produce 'num_samples' draws from the model\n",
    "        for r in range(num_samples):\n",
    "            # forward pass\n",
    "            with torch.no_grad():\n",
    "                output = model(inputs, t=timestamps, training=False)\n",
    "            \n",
    "            # convert from residual to actual\n",
    "            # shape [1, nvars, H, W]\n",
    "            hr_pred = dataset.residual_to_hr(output.cpu(), lrinterp.cpu())\n",
    "\n",
    "            if variable == 'pr':\n",
    "                # For precipitation: use softplus and unit conversion (kg/m²/s to mm/day)\n",
    "                pr_val = cu.softplus(hr_pred[:, 0])\n",
    "                pr_val = cu.kgm2sTommday(pr_val)\n",
    "                pixel_val = pr_val[0, pix_y, pix_x].item()\n",
    "            elif variable == 'tasmax':\n",
    "                # For tasmax: compute as softplus(channel 2, c=0) + channel 1, then convert from Kelvin to Celsius\n",
    "                tasmax = hr_pred[:, 1] + cu.softplus(hr_pred[:, 2], c=0)\n",
    "                tasmax = cu.KToC(tasmax)\n",
    "                pixel_val = tasmax[0, pix_y, pix_x].item()\n",
    "            elif variable == 'tasmin':\n",
    "                tasmin = hr_pred[:, 1]  # No transformation needed for tasmin\n",
    "                tasmin = cu.KToC(tasmin)\n",
    "                pixel_val = tasmin[0, pix_y, pix_x].item()\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported variable. Use 'pr', 'tasmax' or 'tasmin'.\")\n",
    "\n",
    "            daily_data[day_idx, r] = pixel_val\n",
    "\n",
    "    # Now daily_data shape = [total_days, num_samples]. We should have the entire record.\n",
    "\n",
    "    # Next: get block maxima. We must know how many years we have and days_per_year\n",
    "    days_per_year = 365 \n",
    "    n_years = len(years) \n",
    "    # check total_days == n_years * days_per_year, or adapt as needed\n",
    "    print(f\"Total days = {total_days}, years = {n_years}, days_per_year = {days_per_year}\")\n",
    "    \n",
    "    block_maxima = compute_annual_block_maxima(daily_data, years, days_per_year=days_per_year)\n",
    "    # block_maxima => shape (#years * num_samples,)\n",
    "\n",
    "    # Fit GEV\n",
    "    shape_hat, loc_hat, scale_hat = genextreme.fit(block_maxima)\n",
    "    print(f\"GEV fit => shape={shape_hat:.3f}, loc={loc_hat:.3f}, scale={scale_hat:.3f}\")\n",
    "\n",
    "    np.save(f\"{args.plotdir}/pixel_{pix_y}_{pix_x}_block_maxima.npy\", block_maxima)\n",
    "\n",
    "    # We define which return periods we want\n",
    "    return_periods = [2, 5, 10, 20, 50, 100, 200, 300, 500, 700, 1000]\n",
    "    # Compute return levels\n",
    "    rl_values = [gev_return_level(shape_hat, loc_hat, scale_hat, T) for T in return_periods]\n",
    "\n",
    "    # Bootstrap for confidence intervals\n",
    "    rl_boot = gev_parametric_bootstrap(shape_hat, loc_hat, scale_hat,\n",
    "                                       sample_size=len(block_maxima),\n",
    "                                       return_periods=return_periods,\n",
    "                                       n_bootstrap=1000)  \n",
    "\n",
    "    rl_ci_lower = {}\n",
    "    rl_ci_upper = {}\n",
    "    for T in return_periods:\n",
    "        vals_T = np.array(rl_boot[T])\n",
    "        rl_ci_lower[T] = np.percentile(vals_T, 2.5)\n",
    "        rl_ci_upper[T] = np.percentile(vals_T, 97.5)\n",
    "\n",
    "    print(\"\\nReturn Levels (mm/day) with 95% CI at the chosen pixel:\")\n",
    "    for T, rl in zip(return_periods, rl_values):\n",
    "        ci_low = rl_ci_lower[T]\n",
    "        ci_high = rl_ci_upper[T]\n",
    "        print(f\"  {T:3d}-year RL = {rl:.2f}  [95% CI: {ci_low:.2f}, {ci_high:.2f}]\")\n",
    "\n",
    "  \n",
    "    plt.figure(figsize=(8,5))\n",
    "    Ts = np.array(return_periods)\n",
    "    rl_means = np.array(rl_values)\n",
    "    rl_low = np.array([rl_ci_lower[T] for T in return_periods])\n",
    "    rl_high= np.array([rl_ci_upper[T] for T in return_periods])\n",
    "\n",
    "    # Plot GEV fit and confidence interval\n",
    "    plt.plot(Ts, rl_means, marker='o', color='blue', label='Fitted Return Level')\n",
    "    plt.fill_between(Ts, rl_low, rl_high, alpha=0.2, color='blue', label='95% CI')\n",
    "\n",
    "    # Calculate empirical return periods and sort block maxima\n",
    "    sorted_maxima, empirical_T = get_empirical_return_periods(block_maxima)\n",
    "\n",
    "    # Plot the empirical points\n",
    "    plt.scatter(empirical_T, sorted_maxima, marker='x', color='red', s=30, label='Empirical Data')\n",
    "\n",
    "    plt.xscale('log')\n",
    "    if variable == 'pr':\n",
    "        plt.ylabel('Precipitation (mm/day)')\n",
    "        plt.title(f\"Precipitation GEV Return Levels at Pixel ({pix_y},{pix_x})\")\n",
    "    elif variable == 'tasmax':\n",
    "        plt.ylabel('Tasmax (°C)')\n",
    "        plt.title(f\"Tasmax GEV Return Levels at Pixel ({pix_y},{pix_x})\")\n",
    "    elif variable == 'tasmin':\n",
    "        plt.ylabel('Tasmin (°C)')\n",
    "        plt.title(f\"Tasmin GEV Return Levels at Pixel ({pix_y},{pix_x})\")\n",
    "\n",
    "    plt.xlabel('Return Period (years)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure or show\n",
    "    plt.savefig(f\"{args.plotdir}/pixel_{pix_y}_{pix_x}_return_levels.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    return daily_data, block_maxima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening and lazy loading netCDF files\n",
      "Loading dataset into memory\n",
      "Converting xarray Dataset to Pytorch tensor\n",
      "\n",
      "##########################################\n",
      "############ PROCESSING DONE #############\n",
      "##########################################\n",
      "\n",
      "Test dataset length (days): 10950\n"
     ]
    }
   ],
   "source": [
    "args.years_test = range(1998, 2028)\n",
    "dataset_test = cu.climex2torch(\n",
    "    datadir=args.datadir,\n",
    "    years=args.years_test,\n",
    "    variables=args.variables,\n",
    "    coords=args.coords,\n",
    "    lowres_scale=args.lowres_scale,\n",
    "    type=\"lrinterp_to_residuals\",\n",
    "    transfo=True\n",
    ")\n",
    "\n",
    "print(\"Test dataset length (days):\", len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prob_unet import ProbabilisticUNet\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create your model with the same structure:\n",
    "probunet_model = ProbabilisticUNet(\n",
    "    input_channels=len(args.variables),\n",
    "    num_classes=len(args.variables),\n",
    "    latent_dim=16,\n",
    "    num_filters=[32, 64, 128, 256],\n",
    "    model_channels=32,\n",
    "    channel_mult=[1, 2, 4, 8],\n",
    "    beta_0=0.0,\n",
    "    beta_1=0.0,\n",
    "    beta_2=0.0\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the trained weights\n",
    "checkpoint_path = \"./results/plots/08/01/202508:49:05/probunet_model_lat_dim_16.pth\"\n",
    "probunet_model.load_state_dict(\n",
    "    torch.load(checkpoint_path, map_location=device)\n",
    ")\n",
    "probunet_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Computing return levels at pixel = (56, 40).\n",
      "\n",
      "[INFO] number of samples = 30\n",
      "\n",
      "[INFO] variable = pr\n",
      "Computing statistics for standardization\n",
      "Total days = 10950, years = 30, days_per_year = 365\n",
      "GEV fit => shape=-0.007, loc=41.307, scale=10.524\n",
      "\n",
      "Return Levels (mm/day) with 95% CI at the chosen pixel:\n",
      "    2-year RL = 45.17  [95% CI: 44.38, 46.02]\n",
      "    5-year RL = 57.18  [95% CI: 55.98, 58.39]\n",
      "   10-year RL = 65.18  [95% CI: 63.44, 66.91]\n",
      "   20-year RL = 72.90  [95% CI: 70.41, 75.37]\n",
      "   50-year RL = 82.96  [95% CI: 79.12, 86.75]\n",
      "  100-year RL = 90.53  [95% CI: 85.56, 95.81]\n",
      "  200-year RL = 98.12  [95% CI: 91.63, 105.33]\n",
      "  300-year RL = 102.57  [95% CI: 95.18, 110.92]\n",
      "  500-year RL = 108.19  [95% CI: 99.58, 118.21]\n",
      "  700-year RL = 111.90  [95% CI: 102.39, 123.04]\n",
      "  1000-year RL = 115.85  [95% CI: 105.25, 128.24]\n"
     ]
    }
   ],
   "source": [
    "daily_data, block_maxima = compute_return_levels_for_random_pixel(\n",
    "    model=probunet_model,\n",
    "    dataset=dataset_test,\n",
    "    device=device,\n",
    "    years=args.years_test,      \n",
    "    num_samples=30,        \n",
    "    chosen_pixel=(56, 40),\n",
    "    variable= \"pr\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Computing return levels at pixel = (56, 40).\n",
      "\n",
      "[INFO] number of samples = 10\n",
      "\n",
      "[INFO] variable = tasmax\n",
      "Computing statistics for standardization\n",
      "Total days = 10950, years = 30, days_per_year = 365\n",
      "GEV fit => shape=0.156, loc=33.022, scale=1.973\n",
      "\n",
      "Return Levels (mm/day) with 95% CI at the chosen pixel:\n",
      "    2-year RL = 33.72  [95% CI: 33.47, 33.98]\n",
      "    5-year RL = 35.66  [95% CI: 35.34, 35.96]\n",
      "   10-year RL = 36.77  [95% CI: 36.38, 37.12]\n",
      "   20-year RL = 37.71  [95% CI: 37.21, 38.16]\n",
      "   50-year RL = 38.78  [95% CI: 38.10, 39.40]\n",
      "  100-year RL = 39.49  [95% CI: 38.67, 40.27]\n",
      "  200-year RL = 40.13  [95% CI: 39.14, 41.09]\n",
      "  300-year RL = 40.47  [95% CI: 39.38, 41.55]\n",
      "  500-year RL = 40.86  [95% CI: 39.65, 42.11]\n",
      "  700-year RL = 41.11  [95% CI: 39.82, 42.46]\n",
      "  1000-year RL = 41.35  [95% CI: 39.97, 42.81]\n"
     ]
    }
   ],
   "source": [
    "daily_data_tasmax, block_maxima_tasmax = compute_return_levels_for_random_pixel(\n",
    "    model=probunet_model,\n",
    "    dataset=dataset_test,\n",
    "    device=device,\n",
    "    years=args.years_test,      \n",
    "    num_samples=10,        \n",
    "    chosen_pixel=(56, 40),\n",
    "    variable= \"tasmax\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Computing return levels at pixel = (56, 40).\n",
      "\n",
      "[INFO] number of samples = 10\n",
      "\n",
      "[INFO] variable = tasmin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m daily_data_tasmin, block_maxima_tasmin \u001b[38;5;241m=\u001b[39m compute_return_levels_for_random_pixel(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mprobunet_model,\n\u001b[1;32m      3\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset_test,\n\u001b[1;32m      4\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m      5\u001b[0m     years\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39myears_test,      \n\u001b[1;32m      6\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,        \n\u001b[1;32m      7\u001b[0m     chosen_pixel\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m56\u001b[39m, \u001b[38;5;241m40\u001b[39m),\n\u001b[1;32m      8\u001b[0m     variable\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtasmin\u001b[39m\u001b[38;5;124m\"\u001b[39m    \n\u001b[1;32m      9\u001b[0m )\n",
      "Cell \u001b[0;32mIn[15], line 44\u001b[0m, in \u001b[0;36mcompute_return_levels_for_random_pixel\u001b[0;34m(model, dataset, device, years, num_samples, chosen_pixel, variable)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 44\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(inputs, t\u001b[38;5;241m=\u001b[39mtimestamps, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# convert from residual to actual\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# shape [1, nvars, H, W]\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     hr_pred \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mresidual_to_hr(output\u001b[38;5;241m.\u001b[39mcpu(), lrinterp\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/prob-unet-mds/prob_unet.py:209\u001b[0m, in \u001b[0;36mProbabilisticUNet.forward\u001b[0;34m(self, x, target, t, training)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03mForward pass of the Probabilistic U-Net.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    output (torch.Tensor): The model's output tensor.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Get features from the UNet backbone      \u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m unet_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet(x)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# During training, sample z from the posterior\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;129;01mand\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/prob-unet-mds/networks.py:322\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    320\u001b[0m skips \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 322\u001b[0m     x \u001b[38;5;241m=\u001b[39m block(x, emb) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(block, UNetBlock) \u001b[38;5;28;01melse\u001b[39;00m block(x)\n\u001b[1;32m    323\u001b[0m     skips\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskips_postunet \u001b[38;5;241m=\u001b[39m skips[:\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/prob-unet-mds/networks.py:168\u001b[0m, in \u001b[0;36mUNetBlock.forward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, emb):\n\u001b[1;32m    167\u001b[0m     orig \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 168\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv0(silu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm0(x)))\n\u001b[1;32m    170\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffine(emb)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madaptive_scale:\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1535\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1535\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1536\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "daily_data_tasmin, block_maxima_tasmin = compute_return_levels_for_random_pixel(\n",
    "    model=probunet_model,\n",
    "    dataset=dataset_test,\n",
    "    device=device,\n",
    "    years=args.years_test,      \n",
    "    num_samples=10,        \n",
    "    chosen_pixel=(56, 40),\n",
    "    variable= \"tasmin\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observed vs. Model Return Levels Analysis\n",
    "\n",
    "The plot comparing observed vs. model precipitation return levels reveals several important insights:\n",
    "\n",
    "## Why are there fewer blue crosses (observed empirical) than red crosses (model empirical)?\n",
    "\n",
    "This difference is due to sample size:\n",
    "- **Observed data**: We have 30 years (1998-2028) with 1 observation per year = 30 empirical points\n",
    "- **Model data**: We have 30 years with 30 samples per year = 900 empirical points (30×30)\n",
    "\n",
    "This 30x difference explains the density difference in empirical markers.\n",
    "\n",
    "## Interpretation of the Results:\n",
    "\n",
    "1. **Model Underestimation**: The model GEV curve (red) falls significantly below the observed GEV curve (blue), indicating that our model systematically underestimates precipitation extremes.\n",
    "\n",
    "2. **Statistical Significance**: The model curve falls outside the 95% confidence interval (blue shaded area) of observed GEV for most return periods, confirming this bias is statistically significant.\n",
    "\n",
    "3. **Distribution Behavior**: \n",
    "   - **Observed data**: The empirical blue crosses align well with the fitted GEV curve\n",
    "   - **Model data**: The empirical red crosses show a plateau around 75 mm/day, while the fitted model GEV continues rising - suggesting the model has an artificial ceiling for extreme precipitation\n",
    "\n",
    "4. **Return Period Sensitivity**: The underestimation grows more severe for longer return periods, indicating our model particularly struggles with very extreme events.\n",
    "\n",
    "5. **Physical Limitations**: The plateau in model empirical points suggests our probabilistic U-Net may have inherent limitations in generating sufficiently extreme precipitation events.\n",
    "\n",
    "This analysis confirms our professor's approach was valuable - comparing against observed data reveals systematic biases that weren't apparent when only analyzing the model's internal consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the ratio between model and observed return levels\n",
    "# to quantify the magnitude of the bias\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import genextreme\n",
    "\n",
    "# First, load or calculate the necessary data if not already available\n",
    "obs_block_maxima = np.load(f\"{args.plotdir}/observed_pixel_56_40_block_maxima_pr.npy\")\n",
    "model_block_maxima = np.load(f\"{args.plotdir}/pixel_56_40_block_maxima.npy\")\n",
    "\n",
    "# Fit GEV to both datasets\n",
    "obs_shape, obs_loc, obs_scale = genextreme.fit(obs_block_maxima)\n",
    "model_shape, model_loc, model_scale = genextreme.fit(model_block_maxima)\n",
    "\n",
    "print(f\"Observed GEV parameters: shape={obs_shape:.3f}, loc={obs_loc:.3f}, scale={obs_scale:.3f}\")\n",
    "print(f\"Model GEV parameters: shape={model_shape:.3f}, loc={model_loc:.3f}, scale={model_scale:.3f}\")\n",
    "\n",
    "# Define return periods\n",
    "return_periods = [2, 5, 10, 20, 50, 100, 200, 500, 1000]\n",
    "\n",
    "# Calculate return levels\n",
    "obs_rl = [gev_return_level(obs_shape, obs_loc, obs_scale, T) for T in return_periods]\n",
    "model_rl = [gev_return_level(model_shape, model_loc, model_scale, T) for T in return_periods]\n",
    "\n",
    "# Calculate ratios\n",
    "ratios = np.array(model_rl) / np.array(obs_rl)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(return_periods, ratios, 'o-', color='purple', linewidth=2)\n",
    "plt.axhline(y=1.0, color='k', linestyle='--', alpha=0.5)  # Reference line for no bias\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Return Period (years)')\n",
    "plt.ylabel('Model/Observed Return Level Ratio')\n",
    "plt.title('Relative Bias in Precipitation Return Levels')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{args.plotdir}/return_level_bias_ratio.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
